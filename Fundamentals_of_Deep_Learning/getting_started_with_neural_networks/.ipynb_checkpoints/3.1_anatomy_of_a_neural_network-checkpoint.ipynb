{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85751ec",
   "metadata": {},
   "source": [
    "training a neural network revolves around the following objects:\n",
    "- the 'layers' - which are combined into a network(or model)\n",
    "- the 'input data' and corresponding 'targets'\n",
    "- the 'loss function' - which defines the feedback signal used for learning\n",
    "- the 'optimiser' - which determines how learning proceeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2e0e4",
   "metadata": {},
   "source": [
    "![Layer Loss Optimiser](./layer_loss_opt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a2344",
   "metadata": {},
   "source": [
    "\"the network, composed of layers that are chained together, maps the input data to predictions, the loss function then compares these predictions to targets, producing a loss value: a measure of how well the network's predicitons match what was expected. the optimiser uses this loss value to update the network's weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8002cf",
   "metadata": {},
   "source": [
    "##### Layers: the Building Blocks of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597f6a7",
   "metadata": {},
   "source": [
    "layer, the fundamental data structure in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de6b3a",
   "metadata": {},
   "source": [
    "a layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c65adc",
   "metadata": {},
   "source": [
    "some layers are stateless, but morefrequently layers have a state: the layer's weights. one or several tensors learned with stochastic gradient descent, which together contain the network's 'knowledge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a818427",
   "metadata": {},
   "source": [
    "different layers are appropriate for different tensor formats and different types of data processing\n",
    "- simple vector data: stored in 2D tensors of shape (samples, features), is often processed by 'densely connected layers', also called 'fully connected' or 'dense layers'\n",
    "- sequence data: stored in 3D tensors of shape (samples, timesteps, features), is typically processed by 'recurrent layers' such as an LSTM layer\n",
    "- image data: stored in 4D tensors, is usually processed by 2D concolution layers (Conv2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16587d4",
   "metadata": {},
   "source": [
    "building deep-learning models in Keras is done by clipping together compatible layersto form useful data-transformation piplines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d9317",
   "metadata": {},
   "source": [
    "'layer compatibility' - every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fafec",
   "metadata": {},
   "source": [
    "the first layer will only accept as input 2D tensors where the first dimension is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be accepted), the layer will return a tensor where the first dimension has been transformed to be 32 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189467a",
   "metadata": {},
   "source": [
    "thus this layer can only be connected to a downstream layer that expects 32 dimensional vectors as its input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dbad7",
   "metadata": {},
   "source": [
    "keras are built to dynamically match the shape of the incoming layer, the second layer did not receive an input shape arguement - instead, it automatically inferred its input shape as being the output shape of the layer that came before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74c244",
   "metadata": {},
   "source": [
    "##### Models: Networks of Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960cc5e",
   "metadata": {},
   "source": [
    "a deep learning model is a directed, acyclic graph of layers, the most common instance is a linear stack of layers, mapping a single input to a single output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664d9d4",
   "metadata": {},
   "source": [
    "variety of network topologies:\n",
    "- two-branch networks\n",
    "- multihead networks\n",
    "- inception blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71f926",
   "metadata": {},
   "source": [
    "the topology of a network defines a 'hypothesis space', we defined machine learning as \"searching for useful representations of some input data, within a predefined space of possibilities, using fuidance from a feedback signal\", by choosing a network topology, you constrain your 'space of possibilities' (hypothesis space) to a specific series of tensor operations, mapping input data to output data, what then will be searching is a good set of values for the weight tensors involved in these tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a537c9",
   "metadata": {},
   "source": [
    "picking the right network architecture is more an art than a scinece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7df721",
   "metadata": {},
   "source": [
    "##### Loss Function and Optimisers: Keys to Configuring the Learning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9e5e7",
   "metadata": {},
   "source": [
    "there are two more things once the network architecture is defined:\n",
    "- loss function -- the quantity that will be minimised during training, it represents a measure of success for the task at hand\n",
    "- optimizer -- Determines how the network will be updated base on the loss function, it implements a specific variant of stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ceff91",
   "metadata": {},
   "source": [
    " a neural network that has multiple outputs may have multiple loss functoins (one per output), but the gradient-descent process must be based on a single scalar loss value; so for multiloss networks, all losses are combined (via averaging) into a single scalar quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b54d6",
   "metadata": {},
   "source": [
    "choosing the right objective function for the right problemis extermely importanat, if the objective doesn't fully correlate with success for the task at hand, the network will end up doing things you may not have wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8eb60",
   "metadata": {},
   "source": [
    "choose the objective wisely, or you will have to face unintended side effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e9211",
   "metadata": {},
   "source": [
    "there are simple guidelines to choose the correct loss when it comes to common problemssuch as classification, regression, and sequence prediction:\n",
    "- binary crossentropy for a two-class classification problem\n",
    "- categorical crossentropy for a many-class classification problem\n",
    "- mean-squared error for a regression problem\n",
    "- connectionist temporal classification (CTC) for a sequence-learning problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
