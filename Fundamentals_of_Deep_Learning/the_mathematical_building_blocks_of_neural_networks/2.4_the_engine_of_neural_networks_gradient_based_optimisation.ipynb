{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0780ce9c",
   "metadata": {},
   "source": [
    "each neural layer transform its input data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = relu(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf5f84",
   "metadata": {},
   "source": [
    "in this expression, 'W' and 'b' are tensors that are attributes of the layer, they're called the 'weight' and 'trainable parameters' of the layer (the 'kernel' and 'bias' attributes, respectively), these weights contain the information learned by the network from exposure to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34da80",
   "metadata": {},
   "source": [
    "initially, these weight matrices are filled with small random values (a step called random initialisation), these weights are then gradually to adjust, based on a feedback signal (training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c4788",
   "metadata": {},
   "source": [
    "training loops:(repeat as long as necessary)\n",
    "- draw a batch of training samples x and corresponding targets y \n",
    "- run the network on x (a step called 'forward pass') to obtain predictions 'y_pred'\n",
    "- compute the loss of the network on the batch, a measure of the missmatch between 'y_pred' and y\n",
    "- update all weights of the network in a way that slightly reduces the loss on this batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483d024",
   "metadata": {},
   "source": [
    "eventually it will end up with a network that has a very low loss on its training data: a low mismatch between predictions 'y_pred' and y, the network has learned to map its inputs to correct targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18529dcc",
   "metadata": {},
   "source": [
    "updating the network's weights requires the operation of derivates and gradients (less expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bce9b4",
   "metadata": {},
   "source": [
    "##### What's a Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c265e4a",
   "metadata": {},
   "source": [
    "![Derivative](./derivative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38308a97",
   "metadata": {},
   "source": [
    "##### Derivative of a Tensor Operation: the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc7b7f",
   "metadata": {},
   "source": [
    "a gradient is the derivative of a tensor operation, it's the generalisation of the concept of derivatives to function of multidimensional inputs: that is, to functions that take tensors as inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6841a20",
   "metadata": {},
   "source": [
    "consider an input vector ‘x’, a matrix 'W', a target 'y', and a loss function 'loss' that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dot(W, x)\n",
    "loss_value = loss(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ec9c5",
   "metadata": {},
   "source": [
    "if the data inputs 'x' and 'y' are frozen, then this can be interpreted as a function mapping values of 'W' to 'loss value':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4aa793",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value = f(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fefe10",
   "metadata": {},
   "source": [
    "![Derivative of a Tensor Operation: the Gradient](./gradient.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacd552",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5241ff",
   "metadata": {},
   "source": [
    "given a differentiable function, it's theoretically possible to find its minimum analyticaaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913527d",
   "metadata": {},
   "source": [
    "applied to a neural network, that means finding analytically the combination of weight values that yields the smallest possible loss function, solving the equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(f)(W) = 0 for W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f2f3d",
   "metadata": {},
   "source": [
    "This is a polynomial equation of N variables, where N is the number of coefficients in the network (often tens of millions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a65489",
   "metadata": {},
   "source": [
    "Mini-Batch Stochastic Gradient Descent: (mini-batch SGD)\n",
    "- draw a batch of training samples [x] and corresponding targets [y]\n",
    "- run the network on [x] to obtain predictions [y_pred]\n",
    "- compute the loss of the network on the batch, a measure of the missmatch between [y_pred] and [y]\n",
    "- compute the gradient of the loss with regard to the network's parameters (a backward pass)\n",
    "- move the parameters a little in the oppsite direction from the gradient -- for example [W -= step * gradient] -- thus reducing the loss on the batch a bit\n",
    "\n",
    "the term 'stochastic' refers to the fact that each batch of data is drawn at random ('stochastic' is a scientific synonym of 'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108e460",
   "metadata": {},
   "source": [
    "![sgd](./sgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27ce41",
   "metadata": {},
   "source": [
    "intuitively is's important to pick a reasonable value fot the 'step' factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d861ab",
   "metadata": {},
   "source": [
    "Alternatively: \n",
    "- true SGD (as opposed to mini-batch SGD):\n",
    "    - draw a single sample and target at each iteration, rather than drawing a batch of data\n",
    "- batch SGD (extreme):\n",
    "    - run every step on all data available\n",
    "\n",
    "each update would then be more accurate, but far more expensive, the efficient compromise between these two extremes is to use mini-batches of reasonable size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268d948",
   "metadata": {},
   "source": [
    "![Gradient Descent](./gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31334f",
   "metadata": {},
   "source": [
    "optimisation methods or optimizers:\n",
    "- there exits multiple variants of SGD that differ by taking into account previous weight updates when computing the next weight update. rather than just looking at the current value of the gradient\n",
    "- for instance, SGD with momentum, Adagrad, RMSProp and several others\n",
    "- momentum addresses two issues with SGD: covergence speed and local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1aeb78",
   "metadata": {},
   "source": [
    "![Local Global Minimum](./local_global.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95495dff",
   "metadata": {},
   "source": [
    "around a certain parameter value, if the parameter under consideration were being optimised via SGD with a small learning rate, then the optimisation process would get stuck at the local minimum instead of making its way to the global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b60d0",
   "metadata": {},
   "source": [
    "using momentum draws inspiraion from physics, mentally image that the optimisation process as a small ball rolling down the loss curve, if it has enough momentum, the ball won't get stuck in a ravine and will end up at the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3ffc8",
   "metadata": {},
   "source": [
    "momentum is implemented by moving the ball at each step based not only on the current slope value (current accelaeration) but also on the current velocity (resulting from past acceleration), in practice, this means updating the parameter w based not only on the current gradient value but alos on the previous parameter update, as in this naive implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_velocity = 0 \n",
    "momentum = 0.1\n",
    "while loss > 0.01:\n",
    "    w, loss, gradient = get_current_parameters()\n",
    "    velocity = past_velocity * momentum + learning_rate * gradient\n",
    "    w = w + momentum * velocity - learning_rate * gradient\n",
    "    past_velocity = velocity\n",
    "    update_parameter(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a6589",
   "metadata": {},
   "source": [
    "##### Chaining Derivatives: the Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37c852",
   "metadata": {},
   "source": [
    "in practice, a neural network function consists of many tensor operations chained together, we can not explicityly compute its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a3a30",
   "metadata": {},
   "source": [
    "for instance, a network [f] compose of three tensor operations, [a], [b] and [c], with weight matrices [W1], [W2] and [W3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(W1, W2, W3) = a(W1, b(W2, c(W3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c55f14",
   "metadata": {},
   "source": [
    "calculus tells us that such a chain of functions can be derived following the 'chain rule': f(g(x)) = f'(g(x)) * g'(x), applying the chain rule to the computation of the gradient values of a neural network gives rise to an algorithm called 'Backpropagation' (also sometimes called 'reverse-model differentiation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee076d",
   "metadata": {},
   "source": [
    "Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, applying the chain rule to compute the contributoin that each parameter had in the loss value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc7965",
   "metadata": {},
   "source": [
    "Nowadays, and for years to come, people will implement networks in modern frameworks that are capable of 'symbolic differentiation', such as TensorFlow, this means taht given a chain of operations with a known derivative, they can compute a gradient function for the chain (by applying the chain rule) that maps network parameter values to gradient values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e950b9",
   "metadata": {},
   "source": [
    "when you have access to such a function, the backward pass is reudced to a call to this gradient function, thanks to symbolic differentiation, you will never have to implement the backpropagation algorithm by hand, all you need is a good understanding of how gradient-based optimisation works. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
