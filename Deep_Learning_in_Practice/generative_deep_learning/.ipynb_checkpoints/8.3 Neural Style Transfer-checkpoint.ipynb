{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac74a080",
   "metadata": {},
   "source": [
    "neural style transfer consists of applying the style of a reference image to a target image while conserving the content of the target image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0fe83b",
   "metadata": {},
   "source": [
    "![A Style Transfer Example](./style_trans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbf440",
   "metadata": {},
   "source": [
    "the key notion behind implement style transfer is the same idea that's central to all deep-learning algorithms: define a loss function to specify what to achieve, and minimize this loss: conserving the content of the original image while adopting the style of the reference image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fc722",
   "metadata": {},
   "source": [
    "mathematrically for [content] and [style], an appropriate loss function to minimize:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25923f42",
   "metadata": {},
   "source": [
    "loss = distance(style(reference_image) - style(generated_iamge)) + distance(content(origial_image) - content(generated_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d256b",
   "metadata": {},
   "source": [
    "### The Content Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c2496",
   "metadata": {},
   "source": [
    "activations from earlier layers in a network contain local informaiton about the image, whereas activations from higher layers contain increasingly global, abstract information; the activations of the different layers of a convnet provide a decomposition of the contents of an image over different spatial scales; the content of an image, which is more global and abstract. to be captured by the representations of the upper layers in a convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc72f48",
   "metadata": {},
   "source": [
    "a good candidate for content loss is thus the L2 norm between the activations of an upper layer in a pretrained convnet, computed over the target image, and the activations of teh same layer computed over the generated image; this guarantees that the generated image will look similar to the original target image; assmuing taht the upper layers of a convnet see is really the content of their input images, then this works as a wy to preserve image content "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391da6b1",
   "metadata": {},
   "source": [
    "### The Style Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902365a",
   "metadata": {},
   "source": [
    "capture the apperance of the sylte reference image at all spatial scales extracted by the convnet, not just a single scale; the inner product of the feature maps of a given layer; this inner product can be understaood as representing a map of the correlations between the layer's features; these featrue correlations capture the statistics of the patterns of a particular spatial scale, which empirically correspond to the apperance of the extures found at this scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a47747",
   "metadata": {},
   "source": [
    "the style loss aims to preserve similar internal correaltions within the activations of different layers, across the style-reference image and the generated image ; this guarantees that the textures found at different spatial scales look similar across the style-reference image and the generated image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19875a5",
   "metadata": {},
   "source": [
    "in short, use a pretrained convnet to define a loss that will do the following:\n",
    "- preserve content by maintaining similar high-level layer activations between the target content image and the genenrated image as containing the same things\n",
    "- preserve style by maintaining similar correlations within activations for both low level layers and high-level layers; feature correlations capture textures: the generated image and teh style-reference image should share the same textures at different spatial scales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7910b",
   "metadata": {},
   "source": [
    "### Neural Style Transfer in Keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
